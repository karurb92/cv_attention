{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"ggplot\")\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\n\nimport gc\nimport os\nimport time\nimport random\nfrom datetime import datetime\nfrom keras.datasets import cifar100\nimport pickle\n\nimport keras\nimport keras.backend as K\nfrom keras.datasets import cifar100\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, Flatten, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport albumentations as albu\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-19T16:22:02.404804Z","iopub.execute_input":"2021-11-19T16:22:02.405265Z","iopub.status.idle":"2021-11-19T16:22:11.432868Z","shell.execute_reply.started":"2021-11-19T16:22:02.405161Z","shell.execute_reply":"2021-11-19T16:22:11.43202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"../input/cassava-leaf-disease-classification\"\nTRAIN_PATH = \"../input/cassava-leaf-disease-classification/train_images/\"\nTEST_PATH = \"../input/cassava-leaf-disease-classification/test_images/\"\nMODEL_PATH = (\n    \"../input/vit-base-models-pretrained-pytorch/jx_vit_base_p16_224-80ecf9dd.pth\"\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-19T16:22:11.434331Z","iopub.execute_input":"2021-11-19T16:22:11.434558Z","iopub.status.idle":"2021-11-19T16:22:11.439025Z","shell.execute_reply.started":"2021-11-19T16:22:11.434532Z","shell.execute_reply":"2021-11-19T16:22:11.43778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\n# df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:11.440464Z","iopub.execute_input":"2021-11-19T16:22:11.440685Z","iopub.status.idle":"2021-11-19T16:22:11.458737Z","shell.execute_reply.started":"2021-11-19T16:22:11.44066Z","shell.execute_reply":"2021-11-19T16:22:11.457834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n(X, y), (X_test, y_test) = cifar100.load_data(label_mode=\"coarse\")","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:11.460476Z","iopub.execute_input":"2021-11-19T16:22:11.460686Z","iopub.status.idle":"2021-11-19T16:22:25.175065Z","shell.execute_reply.started":"2021-11-19T16:22:11.460661Z","shell.execute_reply":"2021-11-19T16:22:25.174181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n_classes = 20\n# class_plotted = np.random.choice(range(n_classes), 5, replace = False)\n# print(class_plotted)\n# print(y.reshape(-1))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:25.176087Z","iopub.execute_input":"2021-11-19T16:22:25.176286Z","iopub.status.idle":"2021-11-19T16:22:25.180585Z","shell.execute_reply.started":"2021-11-19T16:22:25.176261Z","shell.execute_reply":"2021-11-19T16:22:25.179605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"The shape of X_train : \", X.shape)\n# print(\"The shape of X_test : \", X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:25.181596Z","iopub.execute_input":"2021-11-19T16:22:25.181799Z","iopub.status.idle":"2021-11-19T16:22:25.192559Z","shell.execute_reply.started":"2021-11-19T16:22:25.181775Z","shell.execute_reply":"2021-11-19T16:22:25.191739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unpickle(file):\n    with open(file, 'rb') as fo:\n        myDict = pickle.load(fo, encoding='latin1')\n    return myDict","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:25.193391Z","iopub.execute_input":"2021-11-19T16:22:25.193605Z","iopub.status.idle":"2021-11-19T16:22:25.20271Z","shell.execute_reply.started":"2021-11-19T16:22:25.193567Z","shell.execute_reply":"2021-11-19T16:22:25.202113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainData = unpickle('../input/cifar100/train')\nmetaData = unpickle(\"../input/cifar100/meta\")\n#type of items in each file\nfor item in trainData:\n    print(item, type(trainData[item]))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:25.203684Z","iopub.execute_input":"2021-11-19T16:22:25.204189Z","iopub.status.idle":"2021-11-19T16:22:28.779821Z","shell.execute_reply.started":"2021-11-19T16:22:25.204158Z","shell.execute_reply":"2021-11-19T16:22:28.778736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(\"Fine labels:\", metaData['fine_label_names'], \"\\n\")\nprint(\"Coarse labels:\", metaData['coarse_label_names'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:28.78165Z","iopub.execute_input":"2021-11-19T16:22:28.782301Z","iopub.status.idle":"2021-11-19T16:22:28.796844Z","shell.execute_reply.started":"2021-11-19T16:22:28.782251Z","shell.execute_reply":"2021-11-19T16:22:28.795083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category = pd.DataFrame(metaData['coarse_label_names'], columns=['SuperClass'])\nprint(category)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:28.800553Z","iopub.execute_input":"2021-11-19T16:22:28.800875Z","iopub.status.idle":"2021-11-19T16:22:28.819805Z","shell.execute_reply.started":"2021-11-19T16:22:28.800836Z","shell.execute_reply":"2021-11-19T16:22:28.818581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = trainData['data']\nX_train = X_train.reshape(len(X_train),3,32,32).transpose(0,2,3,1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:28.821101Z","iopub.execute_input":"2021-11-19T16:22:28.821733Z","iopub.status.idle":"2021-11-19T16:22:28.827434Z","shell.execute_reply.started":"2021-11-19T16:22:28.821687Z","shell.execute_reply":"2021-11-19T16:22:28.826528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_plotted = np.random.choice(range(20), 5, replace = False)\nfor i in range(len(class_plotted)):\n    image_samples = X_train[trainData['coarse_labels'] == class_plotted[i]][:5]\n    fig, ax = plt.subplots(nrows = 1, ncols = 5,figsize = (8,8))\n    fig.suptitle(\"label : %d, class : %s\" % (class_plotted[i], metaData['coarse_label_names'][class_plotted[i]]), y = .6)\n    for j in range(5):\n        ax[j].imshow(image_samples[j])\n        ax[j].axis('off')  \n    fig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:28.828967Z","iopub.execute_input":"2021-11-19T16:22:28.82929Z","iopub.status.idle":"2021-11-19T16:22:30.136441Z","shell.execute_reply.started":"2021-11-19T16:22:28.829251Z","shell.execute_reply":"2021-11-19T16:22:30.135592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"st = StratifiedShuffleSplit(n_splits = 2, test_size = 0.2, random_state = 1)\nfor train_index, val_index in st.split(X, y):\n    X_train, X_val, y_train, y_val = X[train_index], X[val_index], y[train_index], y[val_index]\n    \nprint(\"The number of training data : \", X_train.shape[0])\nprint(\"The number of validation data : \", X_val.shape[0])\n\n#del X, y","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:30.137555Z","iopub.execute_input":"2021-11-19T16:22:30.137782Z","iopub.status.idle":"2021-11-19T16:22:30.496313Z","shell.execute_reply.started":"2021-11-19T16:22:30.137756Z","shell.execute_reply":"2021-11-19T16:22:30.495696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#unused\ndef np_resize(img, shape):\n    return cv2.resize(img, (shape[1], shape[0]), interpolation = cv2.INTER_CUBIC)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:30.497331Z","iopub.execute_input":"2021-11-19T16:22:30.49752Z","iopub.status.idle":"2021-11-19T16:22:30.502439Z","shell.execute_reply.started":"2021-11-19T16:22:30.497497Z","shell.execute_reply":"2021-11-19T16:22:30.501415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.001\nweight_decay = 0.0001\nbatch_size = 256\nnum_epochs = 100\nimage_size = 72  # We'll resize input images to this size\npatch_size = 24  # Size of the patches to be extract from the input images\nnum_patches = (image_size // patch_size) ** 2\nprojection_dim = 64\nnum_heads = 4\ntransformer_units = [\n    projection_dim * 2,\n    projection_dim,\n]  # Size of the transformer layers\ntransformer_layers = 8\nmlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:30.503697Z","iopub.execute_input":"2021-11-19T16:22:30.503888Z","iopub.status.idle":"2021-11-19T16:22:30.512859Z","shell.execute_reply.started":"2021-11-19T16:22:30.503865Z","shell.execute_reply":"2021-11-19T16:22:30.512205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Patches(layers.Layer):\n    def __init__(self, patch_size):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=[1, self.patch_size, self.patch_size, 1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n        return patches","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:30.513897Z","iopub.execute_input":"2021-11-19T16:22:30.514269Z","iopub.status.idle":"2021-11-19T16:22:30.525201Z","shell.execute_reply.started":"2021-11-19T16:22:30.514241Z","shell.execute_reply":"2021-11-19T16:22:30.524205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(4, 4))\nimage = X_train[np.random.choice(range(X_train.shape[0]))]\nplt.imshow(image.astype(\"uint8\"))\nplt.axis(\"off\")\n\nresized_image = tf.image.resize(\n    tf.convert_to_tensor([image]), size=(image_size, image_size)\n)\npatches = Patches(patch_size)(resized_image)\nprint(f\"Image size: {image_size} X {image_size}\")\nprint(f\"Patch size: {patch_size} X {patch_size}\")\nprint(f\"Patches per image: {patches.shape[1]}\")\nprint(f\"Elements per patch: {patches.shape[-1]}\")\n\nn = int(np.sqrt(patches.shape[1]))\nplt.figure(figsize=(4, 4))\nfor i, patch in enumerate(patches[0]):\n    ax = plt.subplot(n, n, i + 1)\n    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:22:30.526191Z","iopub.execute_input":"2021-11-19T16:22:30.52643Z","iopub.status.idle":"2021-11-19T16:22:30.966989Z","shell.execute_reply.started":"2021-11-19T16:22:30.526394Z","shell.execute_reply":"2021-11-19T16:22:30.966206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sequence of patches (Positional Embedding)\n\n\n# ResNet (include_top)","metadata":{},"execution_count":null,"outputs":[]}]}